{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import sagemaker\n",
    "from dotenv import load_dotenv\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.tuner import CategoricalParameter, HyperparameterTuner\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "ROLE = os.environ[\"SM_ARN_ROLE\"]\n",
    "WAND_API_KEY = os.environ[\"WANDB_API_KEY\"]\n",
    "instance_type = \"ml.c4.xlarge\"\n",
    "output_path = f\"s3://{sess.default_bucket()}/digit_classification/models\"\n",
    "code_location = output_path + \"/digit_classification/source\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......................................................................................................................................................................!\n",
      "best model job is at tensorflow-training-230926-0310-002-944c49e0\n",
      "\n",
      "2023-09-26 03:20:51 Starting - Found matching resource for reuse\n",
      "2023-09-26 03:20:51 Downloading - Downloading input data\n",
      "2023-09-26 03:20:51 Training - Training image download completed. Training in progress.\n",
      "2023-09-26 03:20:51 Uploading - Uploading generated training model\n",
      "2023-09-26 03:20:51 Completed - Resource reused by training job: tensorflow-training-230926-0310-003-c66ba9ba\n",
      "best model is saved at s3://sagemaker-us-east-1-633875729936/digit_classification/models/tensorflow-training-230926-0310-002-944c49e0/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "estimator = TensorFlow(\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=\"../digit_classification\",\n",
    "    role=ROLE,\n",
    "    framework_version=\"2.3.1\",\n",
    "    model_dir=\"/opt/ml/model\",\n",
    "    py_version=\"py37\",\n",
    "    instance_type=instance_type,\n",
    "    instance_count=1,\n",
    "    output_path=output_path,\n",
    "    code_location=code_location,\n",
    "    environment={\"WANDB_API_KEY\": WAND_API_KEY},\n",
    "    hyperparameters={\n",
    "        \"epochs\": 3,\n",
    "        \"beta_1\": 0.9,\n",
    "        \"beta_2\": 0.999,\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"lr\": CategoricalParameter([0.0001, 0.001, 0.01]),\n",
    "    \"batch_size\": CategoricalParameter([128, 256, 512]),\n",
    "}\n",
    "\n",
    "objective_metric_name = \"train loss\"\n",
    "objective_type = \"Minimize\"\n",
    "metric_definitions = [\n",
    "    {\"Name\": \"train loss\", \"Regex\": \"train loss: ([0-9\\\\.]+)\"},\n",
    "    {\"Name\": \"train accuracy\", \"Regex\": \"train accuracy: ([0-9\\\\.]+)\"},\n",
    "    {\"Name\": \"test loss\", \"Regex\": \"test loss: ([0-9\\\\.]+)\"},\n",
    "    {\"Name\": \"test accuracy\", \"Regex\": \"test accuracy: ([0-9\\\\.]+)\"},\n",
    "]\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions,\n",
    "    max_jobs=3,\n",
    "    max_parallel_jobs=1,\n",
    "    objective_type=objective_type,\n",
    "    early_stopping_type=\"Off\",  # we can turn on early stopping by setting to 'AUTO' (we need to do it on test loss/accuracy as an objective metric instead of the train)\n",
    "    autotune=False,  # we can turn this to true to do automatic tuning\n",
    ")\n",
    "\n",
    "tuner.fit()\n",
    "print(f\"best model job is at {tuner.best_training_job()}\")\n",
    "print(f\"best model is saved at {tuner.best_estimator().model_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train One Model Locally or on the Cloud\n",
    "\n",
    "If you want to test your code locally and train it using sagemaker with an specified hyperparams you can run below block. Unfortunately sagemaker does not support hyperparameter tunning locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: tensorflow-training-2023-09-26-03-27-07-653\n",
      "INFO:sagemaker.local.image:'Docker Compose' found using Docker CLI.\n",
      "INFO:sagemaker.local.local_session:Starting training job\n",
      "INFO:sagemaker.local.image:Using the long-lived AWS credentials found in session\n",
      "INFO:sagemaker.local.image:docker compose file: \n",
      "networks:\n",
      "  sagemaker-local:\n",
      "    name: sagemaker-local\n",
      "services:\n",
      "  algo-1-6rne8:\n",
      "    command: train\n",
      "    container_name: uwaro26ocq-algo-1-6rne8\n",
      "    environment:\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    image: 763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.3.1-cpu-py37\n",
      "    networks:\n",
      "      sagemaker-local:\n",
      "        aliases:\n",
      "        - algo-1-6rne8\n",
      "    stdin_open: true\n",
      "    tty: true\n",
      "    volumes:\n",
      "    - /tmp/tmpzzhbu2i7/algo-1-6rne8/input:/opt/ml/input\n",
      "    - /tmp/tmpzzhbu2i7/algo-1-6rne8/output/data:/opt/ml/output/data\n",
      "    - /tmp/tmpzzhbu2i7/algo-1-6rne8/output:/opt/ml/output\n",
      "    - /tmp/tmpzzhbu2i7/model:/opt/ml/model\n",
      "version: '2.3'\n",
      "\n",
      "INFO:sagemaker.local.image:docker command: docker compose -f /tmp/tmpzzhbu2i7/docker-compose.yaml up --build --abort-on-container-exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time=\"2023-09-26T03:27:08Z\" level=warning msg=\"a network with name sagemaker-local exists but was not created for project \\\"tmpzzhbu2i7\\\".\\nSet `external: true` to use an existing network\"\n",
      " Container uwaro26ocq-algo-1-6rne8  Creating\n",
      " Container uwaro26ocq-algo-1-6rne8  Created\n",
      "Attaching to uwaro26ocq-algo-1-6rne8\n",
      "uwaro26ocq-algo-1-6rne8  | 2023-09-26 03:27:09.581509: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "uwaro26ocq-algo-1-6rne8  | 2023-09-26 03:27:09.581649: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\n",
      "uwaro26ocq-algo-1-6rne8  | 2023-09-26 03:27:09.601823: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "uwaro26ocq-algo-1-6rne8  | 2023-09-26 03:27:10,529 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\n",
      "uwaro26ocq-algo-1-6rne8  | 2023-09-26 03:27:10,546 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "uwaro26ocq-algo-1-6rne8  | 2023-09-26 03:27:10,575 botocore.credentials INFO     Found credentials in environment variables.\n",
      "uwaro26ocq-algo-1-6rne8  | 2023-09-26 03:27:10,771 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "uwaro26ocq-algo-1-6rne8  | /usr/local/bin/python3.7 -m pip install -r requirements.txt\n",
      "uwaro26ocq-algo-1-6rne8  | Collecting wandb\n",
      "uwaro26ocq-algo-1-6rne8  |   Downloading wandb-0.15.11-py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 31.2 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25hCollecting GitPython!=3.1.29,>=1.0.0\n",
      "uwaro26ocq-algo-1-6rne8  |   Downloading GitPython-3.1.37-py3-none-any.whl (190 kB)\n",
      "\u001b[K     |████████████████████████████████| 190 kB 85.5 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25hCollecting sentry-sdk>=1.0.0\n",
      "uwaro26ocq-algo-1-6rne8  |   Downloading sentry_sdk-1.31.0-py2.py3-none-any.whl (224 kB)\n",
      "\u001b[K     |████████████████████████████████| 224 kB 104.8 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/site-packages (from wandb->-r requirements.txt (line 1)) (5.3.1)\n",
      "uwaro26ocq-algo-1-6rne8  | Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/site-packages (from wandb->-r requirements.txt (line 1)) (2.24.0)\n",
      "uwaro26ocq-algo-1-6rne8  | Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.7/site-packages (from wandb->-r requirements.txt (line 1)) (3.15.0)\n",
      "uwaro26ocq-algo-1-6rne8  | Collecting Click!=8.0.0,>=7.1\n",
      "uwaro26ocq-algo-1-6rne8  |   Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 5.5 MB/s  eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from wandb->-r requirements.txt (line 1)) (53.0.0)\n",
      "uwaro26ocq-algo-1-6rne8  | Collecting appdirs>=1.4.3\n",
      "uwaro26ocq-algo-1-6rne8  |   Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "uwaro26ocq-algo-1-6rne8  | Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/site-packages (from wandb->-r requirements.txt (line 1)) (3.7.4.3)\n",
      "uwaro26ocq-algo-1-6rne8  | Collecting docker-pycreds>=0.4.0\n",
      "uwaro26ocq-algo-1-6rne8  |   Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "uwaro26ocq-algo-1-6rne8  | Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/site-packages (from wandb->-r requirements.txt (line 1)) (5.7.2)\n",
      "uwaro26ocq-algo-1-6rne8  | Collecting setproctitle\n",
      "uwaro26ocq-algo-1-6rne8  |   Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "uwaro26ocq-algo-1-6rne8  | Collecting pathtools\n",
      "uwaro26ocq-algo-1-6rne8  |   Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "uwaro26ocq-algo-1-6rne8  | Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/site-packages (from Click!=8.0.0,>=7.1->wandb->-r requirements.txt (line 1)) (3.4.0)\n",
      "uwaro26ocq-algo-1-6rne8  | Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.7/site-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 1)) (1.15.0)\n",
      "uwaro26ocq-algo-1-6rne8  | Collecting gitdb<5,>=4.0.1\n",
      "uwaro26ocq-algo-1-6rne8  |   Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "\u001b[K     |████████████████████████████████| 62 kB 844 kB/s  eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25hCollecting smmap<6,>=3.0.1\n",
      "uwaro26ocq-algo-1-6rne8  |   Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "uwaro26ocq-algo-1-6rne8  | Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (3.0.4)\n",
      "uwaro26ocq-algo-1-6rne8  | Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (2.10)\n",
      "uwaro26ocq-algo-1-6rne8  | Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (1.25.11)\n",
      "uwaro26ocq-algo-1-6rne8  | Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (2020.12.5)\n",
      "uwaro26ocq-algo-1-6rne8  | Collecting sentry-sdk>=1.0.0\n",
      "uwaro26ocq-algo-1-6rne8  |   Downloading sentry_sdk-1.30.0-py2.py3-none-any.whl (218 kB)\n",
      "\u001b[K     |████████████████████████████████| 218 kB 119.3 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.29.2-py2.py3-none-any.whl (215 kB)\n",
      "\u001b[K     |████████████████████████████████| 215 kB 128.7 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.29.1-py2.py3-none-any.whl (219 kB)\n",
      "\u001b[K     |████████████████████████████████| 219 kB 100.8 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.29.0-py2.py3-none-any.whl (219 kB)\n",
      "\u001b[K     |████████████████████████████████| 219 kB 115.0 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.28.1-py2.py3-none-any.whl (214 kB)\n",
      "\u001b[K     |████████████████████████████████| 214 kB 114.8 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.28.0-py2.py3-none-any.whl (213 kB)\n",
      "\u001b[K     |████████████████████████████████| 213 kB 125.6 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.27.1-py2.py3-none-any.whl (211 kB)\n",
      "\u001b[K     |████████████████████████████████| 211 kB 129.6 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.27.0-py2.py3-none-any.whl (211 kB)\n",
      "\u001b[K     |████████████████████████████████| 211 kB 123.1 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.26.0-py2.py3-none-any.whl (209 kB)\n",
      "\u001b[K     |████████████████████████████████| 209 kB 133.7 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.25.1-py2.py3-none-any.whl (206 kB)\n",
      "\u001b[K     |████████████████████████████████| 206 kB 117.2 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.25.0-py2.py3-none-any.whl (206 kB)\n",
      "\u001b[K     |████████████████████████████████| 206 kB 127.1 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.24.0-py2.py3-none-any.whl (206 kB)\n",
      "\u001b[K     |████████████████████████████████| 206 kB 122.2 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.23.1-py2.py3-none-any.whl (205 kB)\n",
      "\u001b[K     |████████████████████████████████| 205 kB 128.8 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.23.0-py2.py3-none-any.whl (205 kB)\n",
      "\u001b[K     |████████████████████████████████| 205 kB 125.8 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.22.2-py2.py3-none-any.whl (203 kB)\n",
      "\u001b[K     |████████████████████████████████| 203 kB 112.9 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.22.1-py2.py3-none-any.whl (203 kB)\n",
      "\u001b[K     |████████████████████████████████| 203 kB 121.9 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.22.0-py2.py3-none-any.whl (203 kB)\n",
      "\u001b[K     |████████████████████████████████| 203 kB 120.8 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.21.1-py2.py3-none-any.whl (201 kB)\n",
      "\u001b[K     |████████████████████████████████| 201 kB 135.7 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.21.0-py2.py3-none-any.whl (199 kB)\n",
      "\u001b[K     |████████████████████████████████| 199 kB 133.7 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.20.0-py2.py3-none-any.whl (198 kB)\n",
      "\u001b[K     |████████████████████████████████| 198 kB 120.5 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.19.1-py2.py3-none-any.whl (199 kB)\n",
      "\u001b[K     |████████████████████████████████| 199 kB 120.3 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.19.0-py2.py3-none-any.whl (199 kB)\n",
      "\u001b[K     |████████████████████████████████| 199 kB 127.2 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.18.0-py2.py3-none-any.whl (194 kB)\n",
      "\u001b[K     |████████████████████████████████| 194 kB 129.4 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.17.0-py2.py3-none-any.whl (189 kB)\n",
      "\u001b[K     |████████████████████████████████| 189 kB 129.8 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.16.0-py2.py3-none-any.whl (184 kB)\n",
      "\u001b[K     |████████████████████████████████| 184 kB 113.3 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.15.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[K     |████████████████████████████████| 181 kB 129.0 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.14.0-py2.py3-none-any.whl (178 kB)\n",
      "\u001b[K     |████████████████████████████████| 178 kB 127.1 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.13.0-py2.py3-none-any.whl (177 kB)\n",
      "\u001b[K     |████████████████████████████████| 177 kB 128.6 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.12.1-py2.py3-none-any.whl (174 kB)\n",
      "\u001b[K     |████████████████████████████████| 174 kB 120.0 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.12.0-py2.py3-none-any.whl (173 kB)\n",
      "\u001b[K     |████████████████████████████████| 173 kB 123.4 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.11.1-py2.py3-none-any.whl (168 kB)\n",
      "\u001b[K     |████████████████████████████████| 168 kB 119.8 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.11.0-py2.py3-none-any.whl (168 kB)\n",
      "\u001b[K     |████████████████████████████████| 168 kB 108.1 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.10.1-py2.py3-none-any.whl (166 kB)\n",
      "\u001b[K     |████████████████████████████████| 166 kB 131.6 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.10.0-py2.py3-none-any.whl (166 kB)\n",
      "\u001b[K     |████████████████████████████████| 166 kB 133.5 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.9.10-py2.py3-none-any.whl (162 kB)\n",
      "\u001b[K     |████████████████████████████████| 162 kB 67.3 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.9.9-py2.py3-none-any.whl (162 kB)\n",
      "\u001b[K     |████████████████████████████████| 162 kB 93.2 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.9.8-py2.py3-none-any.whl (158 kB)\n",
      "\u001b[K     |████████████████████████████████| 158 kB 109.0 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.9.7-py2.py3-none-any.whl (157 kB)\n",
      "\u001b[K     |████████████████████████████████| 157 kB 110.4 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.9.6-py2.py3-none-any.whl (157 kB)\n",
      "\u001b[K     |████████████████████████████████| 157 kB 108.2 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n",
      "\u001b[K     |████████████████████████████████| 157 kB 116.2 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n",
      "\u001b[K     |████████████████████████████████| 157 kB 109.7 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n",
      "\u001b[K     |████████████████████████████████| 157 kB 109.8 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n",
      "\u001b[K     |████████████████████████████████| 157 kB 97.7 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n",
      "\u001b[K     |████████████████████████████████| 157 kB 106.2 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n",
      "\u001b[K     |████████████████████████████████| 156 kB 108.4 MB/s eta 0:00:01\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.1->wandb->-r requirements.txt (line 1)) (3.4.0)\n",
      "uwaro26ocq-algo-1-6rne8  | Building wheels for collected packages: pathtools\n",
      "uwaro26ocq-algo-1-6rne8  |   Building wheel for pathtools (setup.py) ... \u001b[?25ldone\n",
      "uwaro26ocq-algo-1-6rne8  | \u001b[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8784 sha256=411dbda043ad2f3a2e201c76ed2eea0302cfe074d1f8cad61effb2cbe4775a01\n",
      "uwaro26ocq-algo-1-6rne8  |   Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
      "uwaro26ocq-algo-1-6rne8  | Successfully built pathtools\n",
      "uwaro26ocq-algo-1-6rne8  | Installing collected packages: smmap, gitdb, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, Click, appdirs, wandb\n",
      "uwaro26ocq-algo-1-6rne8  | Successfully installed Click-8.1.7 GitPython-3.1.37 appdirs-1.4.4 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.9.0 setproctitle-1.3.2 smmap-5.0.1 wandb-0.15.11\n",
      "uwaro26ocq-algo-1-6rne8  | WARNING: You are using pip version 21.0.1; however, version 23.2.1 is available.\n",
      "uwaro26ocq-algo-1-6rne8  | You should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\n",
      "uwaro26ocq-algo-1-6rne8  | \n",
      "uwaro26ocq-algo-1-6rne8  | 2023-09-26 03:27:17,506 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "uwaro26ocq-algo-1-6rne8  | 2023-09-26 03:27:17,538 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "uwaro26ocq-algo-1-6rne8  | 2023-09-26 03:27:17,572 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "uwaro26ocq-algo-1-6rne8  | 2023-09-26 03:27:17,588 sagemaker-training-toolkit INFO     Invoking user script\n",
      "uwaro26ocq-algo-1-6rne8  | \n",
      "uwaro26ocq-algo-1-6rne8  | Training Env:\n",
      "uwaro26ocq-algo-1-6rne8  | \n",
      "uwaro26ocq-algo-1-6rne8  | {\n",
      "uwaro26ocq-algo-1-6rne8  |     \"additional_framework_parameters\": {},\n",
      "uwaro26ocq-algo-1-6rne8  |     \"channel_input_dirs\": {},\n",
      "uwaro26ocq-algo-1-6rne8  |     \"current_host\": \"algo-1-6rne8\",\n",
      "uwaro26ocq-algo-1-6rne8  |     \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "uwaro26ocq-algo-1-6rne8  |     \"hosts\": [\n",
      "uwaro26ocq-algo-1-6rne8  |         \"algo-1-6rne8\"\n",
      "uwaro26ocq-algo-1-6rne8  |     ],\n",
      "uwaro26ocq-algo-1-6rne8  |     \"hyperparameters\": {\n",
      "uwaro26ocq-algo-1-6rne8  |         \"batch_size\": 256,\n",
      "uwaro26ocq-algo-1-6rne8  |         \"epochs\": 1,\n",
      "uwaro26ocq-algo-1-6rne8  |         \"lr\": 0.001,\n",
      "uwaro26ocq-algo-1-6rne8  |         \"beta_1\": 0.9,\n",
      "uwaro26ocq-algo-1-6rne8  |         \"beta_2\": 0.999\n",
      "uwaro26ocq-algo-1-6rne8  |     },\n",
      "uwaro26ocq-algo-1-6rne8  |     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "uwaro26ocq-algo-1-6rne8  |     \"input_data_config\": {},\n",
      "uwaro26ocq-algo-1-6rne8  |     \"input_dir\": \"/opt/ml/input\",\n",
      "uwaro26ocq-algo-1-6rne8  |     \"is_master\": true,\n",
      "uwaro26ocq-algo-1-6rne8  |     \"job_name\": \"tensorflow-training-2023-09-26-03-27-07-653\",\n",
      "uwaro26ocq-algo-1-6rne8  |     \"log_level\": 20,\n",
      "uwaro26ocq-algo-1-6rne8  |     \"master_hostname\": \"algo-1-6rne8\",\n",
      "uwaro26ocq-algo-1-6rne8  |     \"model_dir\": \"/opt/ml/model\",\n",
      "uwaro26ocq-algo-1-6rne8  |     \"module_dir\": \"s3://sagemaker-us-east-1-633875729936/tensorflow-training-2023-09-26-03-27-07-653/source/sourcedir.tar.gz\",\n",
      "uwaro26ocq-algo-1-6rne8  |     \"module_name\": \"train\",\n",
      "uwaro26ocq-algo-1-6rne8  |     \"network_interface_name\": \"eth0\",\n",
      "uwaro26ocq-algo-1-6rne8  |     \"num_cpus\": 48,\n",
      "uwaro26ocq-algo-1-6rne8  |     \"num_gpus\": 0,\n",
      "uwaro26ocq-algo-1-6rne8  |     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "uwaro26ocq-algo-1-6rne8  |     \"output_dir\": \"/opt/ml/output\",\n",
      "uwaro26ocq-algo-1-6rne8  |     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "uwaro26ocq-algo-1-6rne8  |     \"resource_config\": {\n",
      "uwaro26ocq-algo-1-6rne8  |         \"current_host\": \"algo-1-6rne8\",\n",
      "uwaro26ocq-algo-1-6rne8  |         \"hosts\": [\n",
      "uwaro26ocq-algo-1-6rne8  |             \"algo-1-6rne8\"\n",
      "uwaro26ocq-algo-1-6rne8  |         ]\n",
      "uwaro26ocq-algo-1-6rne8  |     },\n",
      "uwaro26ocq-algo-1-6rne8  |     \"user_entry_point\": \"train.py\"\n",
      "uwaro26ocq-algo-1-6rne8  | }\n",
      "uwaro26ocq-algo-1-6rne8  | \n",
      "uwaro26ocq-algo-1-6rne8  | Environment variables:\n",
      "uwaro26ocq-algo-1-6rne8  | \n",
      "uwaro26ocq-algo-1-6rne8  | SM_HOSTS=[\"algo-1-6rne8\"]\n",
      "uwaro26ocq-algo-1-6rne8  | SM_NETWORK_INTERFACE_NAME=eth0\n",
      "uwaro26ocq-algo-1-6rne8  | SM_HPS={\"batch_size\":256,\"beta_1\":0.9,\"beta_2\":0.999,\"epochs\":1,\"lr\":0.001}\n",
      "uwaro26ocq-algo-1-6rne8  | SM_USER_ENTRY_POINT=train.py\n",
      "uwaro26ocq-algo-1-6rne8  | SM_FRAMEWORK_PARAMS={}\n",
      "uwaro26ocq-algo-1-6rne8  | SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-6rne8\",\"hosts\":[\"algo-1-6rne8\"]}\n",
      "uwaro26ocq-algo-1-6rne8  | SM_INPUT_DATA_CONFIG={}\n",
      "uwaro26ocq-algo-1-6rne8  | SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "uwaro26ocq-algo-1-6rne8  | SM_CHANNELS=[]\n",
      "uwaro26ocq-algo-1-6rne8  | SM_CURRENT_HOST=algo-1-6rne8\n",
      "uwaro26ocq-algo-1-6rne8  | SM_MODULE_NAME=train\n",
      "uwaro26ocq-algo-1-6rne8  | SM_LOG_LEVEL=20\n",
      "uwaro26ocq-algo-1-6rne8  | SM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\n",
      "uwaro26ocq-algo-1-6rne8  | SM_INPUT_DIR=/opt/ml/input\n",
      "uwaro26ocq-algo-1-6rne8  | SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "uwaro26ocq-algo-1-6rne8  | SM_OUTPUT_DIR=/opt/ml/output\n",
      "uwaro26ocq-algo-1-6rne8  | SM_NUM_CPUS=48\n",
      "uwaro26ocq-algo-1-6rne8  | SM_NUM_GPUS=0\n",
      "uwaro26ocq-algo-1-6rne8  | SM_MODEL_DIR=/opt/ml/model\n",
      "uwaro26ocq-algo-1-6rne8  | SM_MODULE_DIR=s3://sagemaker-us-east-1-633875729936/tensorflow-training-2023-09-26-03-27-07-653/source/sourcedir.tar.gz\n",
      "uwaro26ocq-algo-1-6rne8  | SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1-6rne8\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1-6rne8\"],\"hyperparameters\":{\"batch_size\":256,\"beta_1\":0.9,\"beta_2\":0.999,\"epochs\":1,\"lr\":0.001},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tensorflow-training-2023-09-26-03-27-07-653\",\"log_level\":20,\"master_hostname\":\"algo-1-6rne8\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-633875729936/tensorflow-training-2023-09-26-03-27-07-653/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":48,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-6rne8\",\"hosts\":[\"algo-1-6rne8\"]},\"user_entry_point\":\"train.py\"}\n",
      "uwaro26ocq-algo-1-6rne8  | SM_USER_ARGS=[\"--batch_size\",\"256\",\"--beta_1\",\"0.9\",\"--beta_2\",\"0.999\",\"--epochs\",\"1\",\"--lr\",\"0.001\"]\n",
      "uwaro26ocq-algo-1-6rne8  | SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "uwaro26ocq-algo-1-6rne8  | SM_HP_BATCH_SIZE=256\n",
      "uwaro26ocq-algo-1-6rne8  | SM_HP_EPOCHS=1\n",
      "uwaro26ocq-algo-1-6rne8  | SM_HP_LR=0.001\n",
      "uwaro26ocq-algo-1-6rne8  | SM_HP_BETA_1=0.9\n",
      "uwaro26ocq-algo-1-6rne8  | SM_HP_BETA_2=0.999\n",
      "uwaro26ocq-algo-1-6rne8  | PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python37.zip:/usr/local/lib/python3.7:/usr/local/lib/python3.7/lib-dynload:/usr/local/lib/python3.7/site-packages\n",
      "uwaro26ocq-algo-1-6rne8  | \n",
      "uwaro26ocq-algo-1-6rne8  | Invoking script with the following command:\n",
      "uwaro26ocq-algo-1-6rne8  | \n",
      "uwaro26ocq-algo-1-6rne8  | /usr/local/bin/python3.7 train.py --batch_size 256 --beta_1 0.9 --beta_2 0.999 --epochs 1 --lr 0.001\n",
      "uwaro26ocq-algo-1-6rne8  | \n",
      "uwaro26ocq-algo-1-6rne8  | \n",
      "uwaro26ocq-algo-1-6rne8  | Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "uwaro26ocq-algo-1-6rne8  | Training starts ...\n",
      "uwaro26ocq-algo-1-6rne8  | [2023-09-26 03:27:21.504 27f1f5fde29c:124 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "uwaro26ocq-algo-1-6rne8  | [2023-09-26 03:27:21.544 27f1f5fde29c:124 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "uwaro26ocq-algo-1-6rne8  | epoch 1, train loss: 0.30047205090522766, train accuracy: 90.53666687011719, test loss: 0.07746236026287079, test accuracy: 97.55999755859375\n",
      "uwaro26ocq-algo-1-6rne8  | Config written to: /opt/ml/model/mnist/config.pbtxt\n",
      "uwaro26ocq-algo-1-6rne8  | 2023-09-26 03:27:17.836734: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "uwaro26ocq-algo-1-6rne8  | 2023-09-26 03:27:17.836855: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\n",
      "uwaro26ocq-algo-1-6rne8  | 2023-09-26 03:27:17.857238: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "uwaro26ocq-algo-1-6rne8  | DEBUG:git.cmd:Popen(['git', 'version'], cwd=/opt/ml/code, universal_newlines=False, shell=None, istream=None)\n",
      "uwaro26ocq-algo-1-6rne8  | DEBUG:git.cmd:Popen(['git', 'version'], cwd=/opt/ml/code, universal_newlines=False, shell=None, istream=None)\n",
      "uwaro26ocq-algo-1-6rne8  | DEBUG:wandb.docker.auth:Trying paths: ['/root/.docker/config.json', '/root/.dockercfg']\n",
      "uwaro26ocq-algo-1-6rne8  | DEBUG:wandb.docker.auth:No config file found\n",
      "uwaro26ocq-algo-1-6rne8  | DEBUG:git.util:Failed checking if running in CYGWIN due to: FileNotFoundError(2, \"No such file or directory: '/usr/bin/uname'\")\n",
      "uwaro26ocq-algo-1-6rne8  | DEBUG:wandb.sdk.lib.gitlib:git repository is invalid\n",
      "uwaro26ocq-algo-1-6rne8  | DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "uwaro26ocq-algo-1-6rne8  | DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 None\n",
      "uwaro26ocq-algo-1-6rne8  | DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 None\n",
      "uwaro26ocq-algo-1-6rne8  | wandb: Currently logged in as: a-jahaniamiri (mnist_prototype). Use `wandb login --relogin` to force relogin\n",
      "uwaro26ocq-algo-1-6rne8  | wandb: Tracking run with wandb version 0.15.11\n",
      "uwaro26ocq-algo-1-6rne8  | wandb: Run data is saved locally in /opt/ml/code/wandb/run-20230926_032719-tensorflow-training-2023-09-26-03-27-07-653-vnmqta-algo-1-6rne8\n",
      "uwaro26ocq-algo-1-6rne8  | wandb: Run `wandb offline` to turn off syncing.\n",
      "uwaro26ocq-algo-1-6rne8  | wandb: Syncing run tensorflow-training-2023-09-26-03-27-07-653-vnmqta-algo-1-6rne8\n",
      "uwaro26ocq-algo-1-6rne8  | wandb: ⭐️ View project at https://wandb.ai/mnist_prototype/digit_classification\n",
      "uwaro26ocq-algo-1-6rne8  | wandb: 🚀 View run at https://wandb.ai/mnist_prototype/digit_classification/runs/tensorflow-training-2023-09-26-03-27-07-653-vnmqta-algo-1-6rne8\n",
      "uwaro26ocq-algo-1-6rne8  | WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "uwaro26ocq-algo-1-6rne8  | Instructions for updating:\n",
      "uwaro26ocq-algo-1-6rne8  | This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "uwaro26ocq-algo-1-6rne8  | WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "uwaro26ocq-algo-1-6rne8  | Instructions for updating:\n",
      "uwaro26ocq-algo-1-6rne8  | This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "uwaro26ocq-algo-1-6rne8  | WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "uwaro26ocq-algo-1-6rne8  | Instructions for updating:\n",
      "uwaro26ocq-algo-1-6rne8  | This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "uwaro26ocq-algo-1-6rne8  | WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "uwaro26ocq-algo-1-6rne8  | Instructions for updating:\n",
      "uwaro26ocq-algo-1-6rne8  | This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "uwaro26ocq-algo-1-6rne8  | 2023-09-26 03:27:33.180366: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "uwaro26ocq-algo-1-6rne8  | INFO:tensorflow:Assets written to: /opt/ml/model/mnist/1/model.savedmodel/assets\n",
      "uwaro26ocq-algo-1-6rne8  | INFO:tensorflow:Assets written to: /opt/ml/model/mnist/1/model.savedmodel/assets\n",
      "uwaro26ocq-algo-1-6rne8  | wandb: Waiting for W&B process to finish... (success).\n",
      "wandb: \\ 0.006 MB of 0.006 MB uploaded (0.000 MB deduped)uploaded (0.000 MB deduped)\n",
      "uwaro26ocq-algo-1-6rne8  | wandb: Run history:\n",
      "uwaro26ocq-algo-1-6rne8  | wandb:          epoch ▁\n",
      "uwaro26ocq-algo-1-6rne8  | wandb:  test accuracy ▁\n",
      "uwaro26ocq-algo-1-6rne8  | wandb:      test loss ▁\n",
      "uwaro26ocq-algo-1-6rne8  | wandb: train accuracy ▁\n",
      "uwaro26ocq-algo-1-6rne8  | wandb:     train loss ▁\n",
      "uwaro26ocq-algo-1-6rne8  | wandb: \n",
      "uwaro26ocq-algo-1-6rne8  | wandb: Run summary:\n",
      "uwaro26ocq-algo-1-6rne8  | wandb:          epoch 1\n",
      "uwaro26ocq-algo-1-6rne8  | wandb:  test accuracy 97.56\n",
      "uwaro26ocq-algo-1-6rne8  | wandb:      test loss 0.07746\n",
      "uwaro26ocq-algo-1-6rne8  | wandb: train accuracy 90.53667\n",
      "uwaro26ocq-algo-1-6rne8  | wandb:     train loss 0.30047\n",
      "uwaro26ocq-algo-1-6rne8  | wandb: \n",
      "uwaro26ocq-algo-1-6rne8  | wandb: 🚀 View run tensorflow-training-2023-09-26-03-27-07-653-vnmqta-algo-1-6rne8 at: https://wandb.ai/mnist_prototype/digit_classification/runs/tensorflow-training-2023-09-26-03-27-07-653-vnmqta-algo-1-6rne8\n",
      "uwaro26ocq-algo-1-6rne8  | wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "uwaro26ocq-algo-1-6rne8  | wandb: Find logs at: ./wandb/run-20230926_032719-tensorflow-training-2023-09-26-03-27-07-653-vnmqta-algo-1-6rne8/logs\n",
      "uwaro26ocq-algo-1-6rne8  | DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): o151352.ingest.sentry.io:443\n",
      "uwaro26ocq-algo-1-6rne8  | DEBUG:urllib3.connectionpool:https://o151352.ingest.sentry.io:443 \"POST /api/4504800232407040/envelope/ HTTP/1.1\" 200 2\n",
      "uwaro26ocq-algo-1-6rne8  | \n",
      "uwaro26ocq-algo-1-6rne8  | 2023-09-26 03:27:39,357 sagemaker_tensorflow_container.training WARNING  Your model will NOT be servable with SageMaker TensorFlow Serving containers. The SavedModel bundle is under directory \"model.savedmodel\", not a numeric name.\n",
      "uwaro26ocq-algo-1-6rne8  | 2023-09-26 03:27:39,357 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:copying /tmp/tmpzzhbu2i7/algo-1-6rne8/output/success -> /tmp/tmpzzhbu2i7/artifacts/output\n",
      "INFO:root:creating /tmp/tmpzzhbu2i7/artifacts/output/data\n",
      "INFO:root:creating /tmp/tmpzzhbu2i7/artifacts/model/mnist\n",
      "INFO:root:copying /tmp/tmpzzhbu2i7/model/mnist/config.pbtxt -> /tmp/tmpzzhbu2i7/artifacts/model/mnist\n",
      "INFO:root:creating /tmp/tmpzzhbu2i7/artifacts/model/mnist/1\n",
      "INFO:root:creating /tmp/tmpzzhbu2i7/artifacts/model/mnist/1/model.savedmodel\n",
      "INFO:root:creating /tmp/tmpzzhbu2i7/artifacts/model/mnist/1/model.savedmodel/assets\n",
      "INFO:root:copying /tmp/tmpzzhbu2i7/model/mnist/1/model.savedmodel/saved_model.pb -> /tmp/tmpzzhbu2i7/artifacts/model/mnist/1/model.savedmodel\n",
      "INFO:root:creating /tmp/tmpzzhbu2i7/artifacts/model/mnist/1/model.savedmodel/variables\n",
      "INFO:root:copying /tmp/tmpzzhbu2i7/model/mnist/1/model.savedmodel/variables/variables.data-00000-of-00001 -> /tmp/tmpzzhbu2i7/artifacts/model/mnist/1/model.savedmodel/variables\n",
      "INFO:root:copying /tmp/tmpzzhbu2i7/model/mnist/1/model.savedmodel/variables/variables.index -> /tmp/tmpzzhbu2i7/artifacts/model/mnist/1/model.savedmodel/variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uwaro26ocq-algo-1-6rne8 exited with code 0\n",
      "Aborting on container exit...\n",
      " Container uwaro26ocq-algo-1-6rne8  Stopping\n",
      " Container uwaro26ocq-algo-1-6rne8  Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:copying /tmp/tmpzzhbu2i7/compressed_artifacts/model.tar.gz -> /app/sagemaker_scripts/models/digit_classification\n",
      "INFO:root:copying /tmp/tmpzzhbu2i7/compressed_artifacts/output.tar.gz -> /app/sagemaker_scripts/models/digit_classification\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Job Complete =====\n",
      "Model artifact saved at:\n",
      " file://models/digit_classification/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "local_mode = True\n",
    "output_path = f\"s3://{sess.default_bucket()}/digit_classification/models\"\n",
    "\n",
    "if local_mode:\n",
    "    instance_type = \"local\"\n",
    "    output_path = \"file://models/digit_classification\"  ## comment it if you want to upload the model to the cloud for production\n",
    "    code_location = None\n",
    "\n",
    "estimator = TensorFlow(\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=\"../digit_classification\",\n",
    "    role=ROLE,\n",
    "    framework_version=\"2.3.1\",\n",
    "    model_dir=False,\n",
    "    py_version=\"py37\",\n",
    "    instance_type=instance_type,\n",
    "    instance_count=1,\n",
    "    volume_size=50,\n",
    "    output_path=output_path,\n",
    "    code_location=code_location,\n",
    "    hyperparameters={\n",
    "        \"batch_size\": 256,\n",
    "        \"epochs\": 1,\n",
    "        \"lr\": 1e-3,\n",
    "        \"beta_1\": 0.9,\n",
    "        \"beta_2\": 0.999,\n",
    "    },\n",
    "    environment={\"WANDB_API_KEY\": WAND_API_KEY},\n",
    ")\n",
    "\n",
    "estimator.fit()\n",
    "tf_mnist_model_data = estimator.model_data\n",
    "print(\"Model artifact saved at:\\n\", tf_mnist_model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Nvidia Triton locally\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.08-py3: Pulling from nvidia/tritonserver\n",
      "Digest: sha256:b88ed20fe7daa16c4d45cbc931b3e3fc18be8b206a4aac6f04e40022151eaa93\n",
      "Status: Image is up to date for nvcr.io/nvidia/tritonserver:23.08-py3\n",
      "nvcr.io/nvidia/tritonserver:23.08-py3\n",
      "WARNING: Published ports are discarded when using host network mode\n",
      "a78fcc72ae771455b889d4de4675c0d48f02dde8a2b4fe54d37e104dfba36548\n",
      "\n",
      "=============================\n",
      "== Triton Inference Server ==\n",
      "=============================\n",
      "\n",
      "NVIDIA Release 23.08 (build 66820947)\n",
      "Triton Server Version 2.37.0\n",
      "\n",
      "Copyright (c) 2018-2023, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "This container image and its contents are governed by the NVIDIA Deep Learning Container License.\n",
      "By pulling and using the container, you accept the terms and conditions of this license:\n",
      "https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license\n",
      "\n",
      "I0926 03:27:42.512057 1 libtorch.cc:2507] TRITONBACKEND_Initialize: pytorch\n",
      "I0926 03:27:42.512101 1 libtorch.cc:2517] Triton TRITONBACKEND API version: 1.15\n",
      "I0926 03:27:42.512106 1 libtorch.cc:2523] 'pytorch' TRITONBACKEND API version: 1.15\n",
      "I0926 03:27:42.696903 1 pinned_memory_manager.cc:241] Pinned memory pool is created at '0x7fd5fa000000' with size 268435456\n",
      "I0926 03:27:42.697144 1 cuda_memory_manager.cc:107] CUDA memory pool is created on device 0 with size 67108864\n",
      "I0926 03:27:42.698539 1 model_lifecycle.cc:462] loading: mnist:1\n",
      "I0926 03:27:42.944004 1 tensorflow.cc:2577] TRITONBACKEND_Initialize: tensorflow\n",
      "I0926 03:27:42.944034 1 tensorflow.cc:2587] Triton TRITONBACKEND API version: 1.15\n",
      "I0926 03:27:42.944042 1 tensorflow.cc:2593] 'tensorflow' TRITONBACKEND API version: 1.15\n",
      "I0926 03:27:42.944048 1 tensorflow.cc:2617] backend configuration:\n",
      "{\"cmdline\":{\"auto-complete-config\":\"true\",\"backend-directory\":\"/opt/tritonserver/backends\",\"min-compute-capability\":\"6.000000\",\"default-max-batch-size\":\"4\"}}\n",
      "I0926 03:27:42.944348 1 tensorflow.cc:2683] TRITONBACKEND_ModelInitialize: mnist (version 1)\n",
      "2023-09-26 03:27:42.944869: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /opt/ml/model/mnist/1/model.savedmodel\n",
      "2023-09-26 03:27:42.946260: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2023-09-26 03:27:42.946273: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /opt/ml/model/mnist/1/model.savedmodel\n",
      "2023-09-26 03:27:42.946346: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-26 03:27:42.950071: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-26 03:27:42.951419: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-26 03:27:42.951533: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-26 03:27:42.958055: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-26 03:27:42.958186: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-26 03:27:42.958295: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-26 03:27:42.958404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1636] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21164 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:21:00.0, compute capability: 8.6\n",
      "2023-09-26 03:27:42.983671: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "2023-09-26 03:27:42.984417: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2023-09-26 03:27:43.014148: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /opt/ml/model/mnist/1/model.savedmodel\n",
      "2023-09-26 03:27:43.020969: I tensorflow/cc/saved_model/loader.cc:334] SavedModel load for tags { serve }; Status: success: OK. Took 76109 microseconds.\n",
      "I0926 03:27:43.022482 1 tensorflow.cc:2732] TRITONBACKEND_ModelInstanceInitialize: mnist_0 (GPU device 0)\n",
      "2023-09-26 03:27:43.022641: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /opt/ml/model/mnist/1/model.savedmodel\n",
      "2023-09-26 03:27:43.023455: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2023-09-26 03:27:43.023465: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /opt/ml/model/mnist/1/model.savedmodel\n",
      "2023-09-26 03:27:43.023567: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-26 03:27:43.023688: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-26 03:27:43.023788: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-26 03:27:43.023927: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-26 03:27:43.024030: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-26 03:27:43.024124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1636] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21164 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:21:00.0, compute capability: 8.6\n",
      "2023-09-26 03:27:43.025596: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2023-09-26 03:27:43.054199: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /opt/ml/model/mnist/1/model.savedmodel\n",
      "2023-09-26 03:27:43.061191: I tensorflow/cc/saved_model/loader.cc:334] SavedModel load for tags { serve }; Status: success: OK. Took 38551 microseconds.\n",
      "I0926 03:27:43.061477 1 model_lifecycle.cc:819] successfully loaded 'mnist'\n",
      "I0926 03:27:43.061558 1 server.cc:604] \n",
      "+------------------+------+\n",
      "| Repository Agent | Path |\n",
      "+------------------+------+\n",
      "+------------------+------+\n",
      "\n",
      "I0926 03:27:43.061623 1 server.cc:631] \n",
      "+------------+-------------------------------+-------------------------------+\n",
      "| Backend    | Path                          | Config                        |\n",
      "+------------+-------------------------------+-------------------------------+\n",
      "| pytorch    | /opt/tritonserver/backends/py | {}                            |\n",
      "|            | torch/libtriton_pytorch.so    |                               |\n",
      "| tensorflow | /opt/tritonserver/backends/te | {\"cmdline\":{\"auto-complete-co |\n",
      "|            | nsorflow/libtriton_tensorflow | nfig\":\"true\",\"backend-directo |\n",
      "|            | .so                           | ry\":\"/opt/tritonserver/backen |\n",
      "|            |                               | ds\",\"min-compute-capability\": |\n",
      "|            |                               | \"6.000000\",\"default-max-batch |\n",
      "|            |                               | -size\":\"4\"}}                  |\n",
      "|            |                               |                               |\n",
      "|            |                               |                               |\n",
      "+------------+-------------------------------+-------------------------------+\n",
      "\n",
      "I0926 03:27:43.061666 1 server.cc:674] \n",
      "+-------+---------+--------+\n",
      "| Model | Version | Status |\n",
      "+-------+---------+--------+\n",
      "| mnist | 1       | READY  |\n",
      "+-------+---------+--------+\n",
      "\n",
      "I0926 03:27:43.076083 1 metrics.cc:810] Collecting metrics for GPU 0: NVIDIA GeForce RTX 3090\n",
      "I0926 03:27:43.076305 1 metrics.cc:703] Collecting CPU metrics\n",
      "I0926 03:27:43.076411 1 tritonserver.cc:2435] \n",
      "+----------------------------------+------------------------------------------+\n",
      "| Option                           | Value                                    |\n",
      "+----------------------------------+------------------------------------------+\n",
      "| server_id                        | triton                                   |\n",
      "| server_version                   | 2.37.0                                   |\n",
      "| server_extensions                | classification sequence model_repository |\n",
      "|                                  |  model_repository(unload_dependents) sch |\n",
      "|                                  | edule_policy model_configuration system_ |\n",
      "|                                  | shared_memory cuda_shared_memory binary_ |\n",
      "|                                  | tensor_data parameters statistics trace  |\n",
      "|                                  | logging                                  |\n",
      "| model_repository_path[0]         | /opt/ml/model                            |\n",
      "| model_control_mode               | MODE_NONE                                |\n",
      "| strict_model_config              | 0                                        |\n",
      "| rate_limit                       | OFF                                      |\n",
      "| pinned_memory_pool_byte_size     | 268435456                                |\n",
      "| cuda_memory_pool_byte_size{0}    | 67108864                                 |\n",
      "| min_supported_compute_capability | 6.0                                      |\n",
      "| strict_readiness                 | 1                                        |\n",
      "| exit_timeout                     | 30                                       |\n",
      "| cache_enabled                    | 0                                        |\n",
      "+----------------------------------+------------------------------------------+\n",
      "\n",
      "I0926 03:27:43.077650 1 grpc_server.cc:2451] Started GRPCInferenceService at 0.0.0.0:8001\n",
      "I0926 03:27:43.077804 1 http_server.cc:3558] Started HTTPService at 0.0.0.0:8000\n",
      "I0926 03:27:43.118707 1 http_server.cc:187] Started Metrics Service at 0.0.0.0:8002\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "working_directory = os.getcwd()\n",
    "model_path = os.path.join(working_directory, \"models/digit_classification/model.tar.gz\")\n",
    "\n",
    "# unzip the model:\n",
    "!tar -xzf $model_path -C /tmp/models/digit_classification\n",
    "\n",
    "# run docker nvidia triton server\n",
    "command = f\"\"\"\n",
    "            docker run --gpus=all --shm-size=24g --ulimit memlock=-1 --rm -d --net host \\\n",
    "            -p 8000:8000 -p 8001:8001 -p 8002:8002 -p 8080:8080 \\\n",
    "            --ulimit stack=67108864 \\\n",
    "            --env SAGEMAKER_MULTI_MODEL=false \\\n",
    "            --env SAGEMAKER_TRITON_DEFAULT_MODEL_NAME=\"mnist\" \\\n",
    "            -v /tmp/models/digit_classification:/opt/ml/model \\\n",
    "            --name triton-server -t nvcr.io/nvidia/tritonserver:23.08-py3 \\\n",
    "            tritonserver --model-repository /opt/ml/model\n",
    "          \"\"\"\n",
    "!docker pull nvcr.io/nvidia/tritonserver:23.08-py3\n",
    "!{command}\n",
    "time.sleep(2)\n",
    "!docker logs triton-server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model speed using perf_analyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.08-py3-sdk: Pulling from nvidia/tritonserver\n",
      "Digest: sha256:a0c56ad380d1d9c19c87cbcd3940ab27d511ca979d3538f357e4e1be8cdba94f\n",
      "Status: Image is up to date for nvcr.io/nvidia/tritonserver:23.08-py3-sdk\n",
      "nvcr.io/nvidia/tritonserver:23.08-py3-sdk\n",
      "\n",
      "=================================\n",
      "== Triton Inference Server SDK ==\n",
      "=================================\n",
      "\n",
      "NVIDIA Release 23.08 (build 66821657)\n",
      "\n",
      "Copyright (c) 2018-2023, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "This container image and its contents are governed by the NVIDIA Deep Learning Container License.\n",
      "By pulling and using the container, you accept the terms and conditions of this license:\n",
      "https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license\n",
      "\n",
      "*** Measurement Settings ***\n",
      "  Batch size: 1\n",
      "  Service Kind: Triton\n",
      "  Using \"time_windows\" mode for stabilization\n",
      "  Measurement window: 5000 msec\n",
      "  Using synchronous calls for inference\n",
      "  Stabilizing using average latency\n",
      "\n",
      "Request concurrency: 1\n",
      "  Client: \n",
      "    Request count: 19267\n",
      "    Throughput: 1070.22 infer/sec\n",
      "    Avg latency: 933 usec (standard deviation 1982 usec)\n",
      "    p50 latency: 896 usec\n",
      "    p90 latency: 1013 usec\n",
      "    p95 latency: 1094 usec\n",
      "    p99 latency: 1270 usec\n",
      "    Avg HTTP time: 929 usec (send/recv 41 usec + response wait 888 usec)\n",
      "  Server: \n",
      "    Inference count: 19267\n",
      "    Execution count: 19267\n",
      "    Successful request count: 19267\n",
      "    Avg request latency: 783 usec (overhead 14 usec + queue 12 usec + compute input 9 usec + compute infer 741 usec + compute output 6 usec)\n",
      "\n",
      "Inferences/Second vs. Client Average Batch Latency\n",
      "Concurrency: 1, throughput: 1070.22 infer/sec, latency 933 usec\n"
     ]
    }
   ],
   "source": [
    "!docker pull nvcr.io/nvidia/tritonserver:23.08-py3-sdk\n",
    "!docker run --gpus all --rm --net host nvcr.io/nvidia/tritonserver:23.08-py3-sdk perf_analyzer -m mnist --shape input_1:1,28,28,1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
